{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,

   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import logging \n",
    "from botocore.exceptions import ClientError\n",
    "import pandas as pd \n",
    "import io\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Processed_records.parquet from nlp-data-preprocessing to pandas dataframe\n"
     ]
    }
   ],
   "source": [
    "# Function to read the parquet file as pandas dataframe \n",
    "def open_S3_file_as_df(bucket_name, file_name):\n",
    "    \"\"\"Open a S3 parquet file from bucket and filename and return the parquet as pandas dataframe\n",
    "    :param bucket_name: Bucket name\n",
    "    :param file_name: Specific file name to open\n",
    "    :return: body of the file as a string\n",
    "    \"\"\"\n",

    "    try: \n",
    "        s3 = boto3.resource('s3')\n",
    "        object = s3.Object(bucket_name, file_name)\n",
    "        body = object.get()['Body'].read()\n",
    "        df = pd.read_parquet(io.BytesIO(body))\n",
    "        print(f'Loading {file_name} from {bucket_name} to pandas dataframe')\n",
    "        return df\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return e\n",
    "file_name = \"Processed_records.parquet\"\n",
    "bucket_name_nlp = \"nlp-data-preprocessing\"\n",
    "df_en = open_S3_file_as_df(bucket_name_nlp, file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check duplications beore training the models, and slice the data for training. \n",
    "We will use all the data for training the Word2Vec model in this case as our data is not large "
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 4,

   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [

       "((7153, 6),\n",
       " features_properties_id                0\n",
       " features_properties_title_en          0\n",
       " features_properties_description_en    0\n",
       " features_properties_keywords_en       0\n",
       " metadata_en                           0\n",
       " metadata_en_processed                 0\n",
       " metadata_en_preprocessed_token        0\n",

       " dtype: int64,\n",
       " features_properties_id                7153\n",
       " features_properties_title_en          6930\n",
       " features_properties_description_en    5604\n",
       " features_properties_keywords_en       3779\n",
       " metadata_en                           7153\n",

       " metadata_en_processed                 6847\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the shape of the dataframe\n",
    "shape_training = df_en.shape\n",
    "# Count the number of missing values in each column\n",
    "missing_values_training = df_en.isnull().sum()\n",
    "# Count the number of unique values in each column\n",
    "unique_values_training = df_en.nunique()\n",
    "\n",
    "shape_training, missing_values_training, unique_values_training"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6847, 6)"
      ]
     },
     "execution_count": 5,

     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [

    "#TODO: Remove duplicates based on 'metadata_en_preprocessed_token'\n",
    "\"\"\"\n",
    "If a uuid is removed at this step, we will need to think about how to merge with the other parquet files\n",
    "\"\"\"\n",
    "df_en_deduplicated = df_en.drop_duplicates(subset='metadata_en_processed')\n",
    "# Display the first few rows of the deduplicated dataframe\n",
    "df_en_deduplicated.head()\n",
    "# Check the shape of the deduplicated dataframe\n",
    "shape_deduplicated = df_en_deduplicated.shape\n",
    "shape_deduplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,

   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7153, 3)\n"
     ]
    }
   ],
   "source": [
    "# Get a sample of 500 rows as the training data \n",
    "df = df_en[['features_properties_id', 'features_properties_title_en', 'metadata_en_processed']]\n",
    "#df = df.sample(n=500, random_state=1)\n",
    "# Use all data to train the model\n",
    "df.head()\n",
    "print(df.shape)\n",
    "\n",
    "# write out training data to csv\n",
    "df.to_csv('df_training_full.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec using Genism library and spacy library \n",
    "Gensim provides an easy-to-use interface for training Word2Vec models on custom corpora. You can train models from scratch or continue training existing models on new data. Gensim also offers pretrained Word2Vec models for various languages. \n",
    "\n",
    "Word2Vec generates word embeddings, not sentence or document embeddings. In order to compute the similarity between entire texts, we would typically average the word vectors for all words in the text to get a single vector that represents the text. This approach has its limitations, as it doesn't consider the order of words and its semantic meaning, but it can still provide useful results.\n",
    "\n",
    "In this case, we are training a Word2Vec model using our own data. The steps are as below:\n",
    "1. Preprocess the text: Tokenize the 'metadata_en_processed' texts (split them into individual words) because Word2Vec expects a list of sentences, where each sentence is represented as a list of words.\n",
    "2. Train the Word2Vec model on the tokenized texts. We can use the gensim library's Word2Vec implementation for this.\n",
    "\n",
    "3. Use the trained model to convert each sentence in 'metadata_en_preprocessed_token' into a vector.\n",
    "\n",
    "4. Calculate similarity between each vector and all others.\n",
    "\n",
    "5. For each row, find the top 5 rows with the most similar vectors.\n",
    "\n",
    "\n",

    "Please note that Word2Vec models typically need a lot of data to train well. With only 500 unique sentences, the results may not be very reliable. Additionally, it's important to note that Word2Vec is a word embedding model, which represents each word in a high-dimensional space. To represent entire sentences, we would need to do something like taking the average of all word vectors in a sentence. This method might not always capture the semantic meaning of the sentence very well, but it's a common approach when using word embeddings to represent longer texts."

   ]
  },
  {
   "cell_type": "code",

   "execution_count": 7,

   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim import matutils\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {

   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Word2vec model with genism "


   ]
  },
  {
   "cell_type": "code",


   "execution_count": 8,


   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },

    {
     "name": "stderr",
     "output_type": "stream",
     "text": [

      "C:\\Users\\xcai\\AppData\\Local\\Temp\\ipykernel_23500\\385833583.py:10: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",

      "  model.init_sims(replace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [


      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xcai\\AppData\\Local\\Temp\\ipykernel_23500\\385833583.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['features_properties_title_en'].fillna('', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       [-0.074049026, 0.027289702, 0.016700882, 0.073...\n",
       "1       [-0.02858037, -0.02957781, 0.011721299, 0.0860...\n",
       "2       [-0.09283519, -0.016993595, 0.017842524, 0.060...\n",
       "3       [-0.083689615, -0.00096761726, 0.019858327, 0....\n",
       "4       [-0.10750779, 0.0075561353, 0.029387811, 0.160...\n",
       "                              ...                        \n",
       "7338    [-0.07207868, 0.07566401, 0.042431034, -0.0114...\n",
       "7339    [-0.06976483, 0.076250896, 0.044135798, -0.012...\n",
       "7340    [-0.07208346, 0.06931207, 0.040898647, -0.0150...\n",
       "7341    [-0.07353419, 0.06887483, 0.04055026, -0.01561...\n",
       "7342    [-0.02755257, -0.0038945249, 0.011606601, 0.03...\n",
       "Name: metadata_en_processed, Length: 7153, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the input for the Word2Vec model\n",
    "sentences = df['metadata_en_processed'].apply(lambda x: x.split(' ')).tolist()\n",
    "print(type(sentences))\n",
    "#sentences[0:2]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",

    "# Precompute L2-normalized vectors for better performance\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# Function to computing the vector representations of the texts, from sentence to vector \n",
    "def sentence_to_vector(sentence, model):\n",
    "    words = str(sentence).split()\n",
    "    vector = np.mean([model.wv[word] for word in words if word in model.wv.key_to_index], axis=0)\n",
    "    return vector if isinstance(vector, np.ndarray) else np.zeros(model.vector_size)\n",
    "\n",
    "# Convert each sentence in 'metadata_preprocessed' into a vector\n",
    "vectors = df['metadata_en_processed'].apply(sentence_to_vector, model=model)\n",
    "# Replace the missing value in the 'features_properties_title_en' column with an empty string\n",
    "df['features_properties_title_en'].fillna('', inplace=True)\n",
    "print(type(vectors))\n",
    "vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pretrained word2vec model Google News from Genism \n",
    "Gensim provides various pre-trained models for word embeddings like Word2Vec, FastText, GloVe, etc. However, these models are trained on specific corpora (like Google News, Wikipedia, etc.) and might not provide the best embeddings for your specific use case, especially if your text data is domain-specific or uses a specialized vocabulary that is not well-represented in the pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load pretrained model (since intermediate data is not included, the model cannot be refined with additional data)\n",
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "\n",
    "# Preprocess the 'metadata_en_processed' texts\n",
    "sentences = df['metadata_en_processed'].apply(lambda x: str(x).split())\n",
    "\n",
    "# Compute the vector for each 'metadata_en_processed' text\n",
    "vectors = sentences.apply(lambda words: np.mean([model[word] for word in words if word in model.key_to_index], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pretrained wword2vec from spacy \n",
    "the en_core_web_lg model from SpaCy includes word vectors trained on the Common Crawl corpus using the GloVe algorithm by Stanford. These vectors can be used for tasks similar to Word2Vec vector. \n",
    "Note, AWS Lambda has a deployment package size limit of 250MB for functions that include layers. The en_core_web_lg model is quite large (about 800MB), so it might not be suitable for deployment on AWS Lambda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In terminal, run python -m spacy download en_core_web_lg\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Vectorization \n",
    "def sentence_to_vector(sentence):\n",
    "    # Process the sentence\n",
    "    doc = nlp(sentence)\n",
    "    # Return the average of the word vectors\n",
    "    return np.mean(np.array([token.vector for token in doc]), axis=0)\n",
    "\n",
    "vector = df['metadata_en_processed'].apply(sentence_to_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xcai\\AppData\\Local\\Temp\\ipykernel_23500\\516177359.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sim1'], df['sim2'], df['sim3'], df['sim4'], df['sim5'] = \"\", \"\", \"\", \"\", \"\"\n",
      "C:\\Users\\xcai\\AppData\\Local\\Temp\\ipykernel_23500\\516177359.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sim1'], df['sim2'], df['sim3'], df['sim4'], df['sim5'] = \"\", \"\", \"\", \"\", \"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features_properties_id</th>\n",
       "      <th>features_properties_title_en</th>\n",
       "      <th>metadata_en_processed</th>\n",
       "      <th>sim1</th>\n",
       "      <th>sim2</th>\n",
       "      <th>sim3</th>\n",
       "      <th>sim4</th>\n",
       "      <th>sim5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000183ed-8864-42f0-ae43-c4313a860720</td>\n",
       "      <td>Principal Mineral Areas, Producing Mines, and ...</td>\n",
       "      <td>princip miner area produc mine oil ga field 90...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7f245e4d-76c2-4caa-951a-45d1d2051333</td>\n",
       "      <td>Canadian Digital Elevation Model, 1945-2011</td>\n",
       "      <td>canadian digit elev model collect legaci produ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>085024ac-5a48-427a-a2ea-d62af73f2142</td>\n",
       "      <td>Canada's National Earthquake Scenario Catalogue</td>\n",
       "      <td>canada nation earthquak scenario catalogu nati...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03ccfb5c-a06e-43e3-80fd-09d4f8f69703</td>\n",
       "      <td>Temporal Series of the National Air Photo Libr...</td>\n",
       "      <td>tempor seri nation air photo librari napl regi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>488faf70-b50b-4749-ac1c-a1fd44e06f11</td>\n",
       "      <td>Indigenous Mining Agreements</td>\n",
       "      <td>indigen mine agreement indigen mine agreement ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 features_properties_id  \\\n",
       "0  000183ed-8864-42f0-ae43-c4313a860720   \n",
       "1  7f245e4d-76c2-4caa-951a-45d1d2051333   \n",
       "2  085024ac-5a48-427a-a2ea-d62af73f2142   \n",
       "3  03ccfb5c-a06e-43e3-80fd-09d4f8f69703   \n",
       "4  488faf70-b50b-4749-ac1c-a1fd44e06f11   \n",
       "\n",
       "                        features_properties_title_en  \\\n",
       "0  Principal Mineral Areas, Producing Mines, and ...   \n",
       "1        Canadian Digital Elevation Model, 1945-2011   \n",
       "2    Canada's National Earthquake Scenario Catalogue   \n",
       "3  Temporal Series of the National Air Photo Libr...   \n",
       "4                       Indigenous Mining Agreements   \n",
       "\n",
       "                               metadata_en_processed sim1 sim2 sim3 sim4 sim5  \n",
       "0  princip miner area produc mine oil ga field 90...                           \n",
       "1  canadian digit elev model collect legaci produ...                           \n",
       "2  canada nation earthquak scenario catalogu nati...                           \n",
       "3  tempor seri nation air photo librari napl regi...                           \n",
       "4  indigen mine agreement indigen mine agreement ...                           "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate similarity between each vector and all others\n",
    "similarity_matrix = cosine_similarity(np.array(vectors.tolist()))\n",
    "# Initialize new columns for the top 5 similar texts\n",
    "df['sim1'], df['sim2'], df['sim3'], df['sim4'], df['sim5'] = \"\", \"\", \"\", \"\", \"\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7153/7153 [00:13<00:00, 546.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features_properties_id</th>\n",
       "      <th>features_properties_title_en</th>\n",
       "      <th>metadata_en_processed</th>\n",
       "      <th>sim1</th>\n",
       "      <th>sim2</th>\n",
       "      <th>sim3</th>\n",
       "      <th>sim4</th>\n",
       "      <th>sim5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000183ed-8864-42f0-ae43-c4313a860720</td>\n",
       "      <td>Principal Mineral Areas, Producing Mines, and ...</td>\n",
       "      <td>princip miner area produc mine oil ga field 90...</td>\n",
       "      <td>b64179f3-ea0f-4abb-9cc5-85432fc958a0</td>\n",
       "      <td>22b2db8a-dc12-47f2-9737-99d3da921751</td>\n",
       "      <td>8db08fa3-a181-4d9b-b091-0f65270ff18b</td>\n",
       "      <td>7ce2ed0c-cb87-463d-83aa-7ed62a672792</td>\n",
       "      <td>e2b6e799-9f29-87c4-0143-6c7505978508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7f245e4d-76c2-4caa-951a-45d1d2051333</td>\n",
       "      <td>Canadian Digital Elevation Model, 1945-2011</td>\n",
       "      <td>canadian digit elev model collect legaci produ...</td>\n",
       "      <td>768570f8-5761-498a-bd6a-315eb6cc023d</td>\n",
       "      <td>0fe65119-e96e-4a57-8bfe-9d9245fba06b</td>\n",
       "      <td>f5c4e4af-ddc5-4f54-a70b-8390e4a4268e</td>\n",
       "      <td>ff383f5c-0772-46f3-84df-c2cb860d0da2</td>\n",
       "      <td>4ff9312f-a200-4fe6-aac3-00a803afa5d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>085024ac-5a48-427a-a2ea-d62af73f2142</td>\n",
       "      <td>Canada's National Earthquake Scenario Catalogue</td>\n",
       "      <td>canada nation earthquak scenario catalogu nati...</td>\n",
       "      <td>79fdad93-9025-49ad-ba16-c26d718cc070</td>\n",
       "      <td>f2d6263a-8b65-4350-9515-345875c6bebf</td>\n",
       "      <td>2364749d-70a0-4874-956d-a636401ac5a6</td>\n",
       "      <td>ee421d50-dffd-41fb-976c-5bbfec04b2dd</td>\n",
       "      <td>4cedd37e-0023-41fe-8eff-bea45385e469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03ccfb5c-a06e-43e3-80fd-09d4f8f69703</td>\n",
       "      <td>Temporal Series of the National Air Photo Libr...</td>\n",
       "      <td>tempor seri nation air photo librari napl regi...</td>\n",
       "      <td>230f1f6d-353e-4d02-800b-368f4c48dc86</td>\n",
       "      <td>d8627209-bda2-436f-b22b-0eb19fdc6660</td>\n",
       "      <td>4e8e3c6a-c961-4def-bdc7-f24823462818</td>\n",
       "      <td>f129611d-7ca1-418b-8390-ebac5adf958e</td>\n",
       "      <td>f498bb69-3982-4b62-94db-4c0e0065bc17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>488faf70-b50b-4749-ac1c-a1fd44e06f11</td>\n",
       "      <td>Indigenous Mining Agreements</td>\n",
       "      <td>indigen mine agreement indigen mine agreement ...</td>\n",
       "      <td>CGDIWH-118602</td>\n",
       "      <td>82cad281-ff7d-47b3-b2ce-9f794257e86d</td>\n",
       "      <td>CGDIWH-150333</td>\n",
       "      <td>498a6086-e7c3-440c-b4d3-22fc6c5599a9</td>\n",
       "      <td>fa542137-a976-49a6-856d-f1201adb2243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 features_properties_id  \\\n",
       "0  000183ed-8864-42f0-ae43-c4313a860720   \n",
       "1  7f245e4d-76c2-4caa-951a-45d1d2051333   \n",
       "2  085024ac-5a48-427a-a2ea-d62af73f2142   \n",
       "3  03ccfb5c-a06e-43e3-80fd-09d4f8f69703   \n",
       "4  488faf70-b50b-4749-ac1c-a1fd44e06f11   \n",
       "\n",
       "                        features_properties_title_en  \\\n",
       "0  Principal Mineral Areas, Producing Mines, and ...   \n",
       "1        Canadian Digital Elevation Model, 1945-2011   \n",
       "2    Canada's National Earthquake Scenario Catalogue   \n",
       "3  Temporal Series of the National Air Photo Libr...   \n",
       "4                       Indigenous Mining Agreements   \n",
       "\n",
       "                               metadata_en_processed  \\\n",
       "0  princip miner area produc mine oil ga field 90...   \n",
       "1  canadian digit elev model collect legaci produ...   \n",
       "2  canada nation earthquak scenario catalogu nati...   \n",
       "3  tempor seri nation air photo librari napl regi...   \n",
       "4  indigen mine agreement indigen mine agreement ...   \n",
       "\n",
       "                                   sim1                                  sim2  \\\n",
       "0  b64179f3-ea0f-4abb-9cc5-85432fc958a0  22b2db8a-dc12-47f2-9737-99d3da921751   \n",
       "1  768570f8-5761-498a-bd6a-315eb6cc023d  0fe65119-e96e-4a57-8bfe-9d9245fba06b   \n",
       "2  79fdad93-9025-49ad-ba16-c26d718cc070  f2d6263a-8b65-4350-9515-345875c6bebf   \n",
       "3  230f1f6d-353e-4d02-800b-368f4c48dc86  d8627209-bda2-436f-b22b-0eb19fdc6660   \n",
       "4                         CGDIWH-118602  82cad281-ff7d-47b3-b2ce-9f794257e86d   \n",
       "\n",
       "                                   sim3                                  sim4  \\\n",
       "0  8db08fa3-a181-4d9b-b091-0f65270ff18b  7ce2ed0c-cb87-463d-83aa-7ed62a672792   \n",
       "1  f5c4e4af-ddc5-4f54-a70b-8390e4a4268e  ff383f5c-0772-46f3-84df-c2cb860d0da2   \n",
       "2  2364749d-70a0-4874-956d-a636401ac5a6  ee421d50-dffd-41fb-976c-5bbfec04b2dd   \n",
       "3  4e8e3c6a-c961-4def-bdc7-f24823462818  f129611d-7ca1-418b-8390-ebac5adf958e   \n",
       "4                         CGDIWH-150333  498a6086-e7c3-440c-b4d3-22fc6c5599a9   \n",
       "\n",
       "                                   sim5  \n",
       "0  e2b6e799-9f29-87c4-0143-6c7505978508  \n",
       "1  4ff9312f-a200-4fe6-aac3-00a803afa5d9  \n",
       "2  4cedd37e-0023-41fe-8eff-bea45385e469  \n",
       "3  f498bb69-3982-4b62-94db-4c0e0065bc17  \n",
       "4  fa542137-a976-49a6-856d-f1201adb2243  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each text, find the top 5 most similar texts and append their 'features_properties_title_en' as new columns\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "for i in tqdm(range(similarity_matrix.shape[0])):\n",
    "    top_5_similar = np.argsort(-similarity_matrix[i, :])[1:6]  # Exclude the text itself\n",
    "    df.loc[i, ['sim1', 'sim2', 'sim3', 'sim4', 'sim5']] = df.loc[top_5_similar, 'features_properties_id'].values\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('df_training_full_sim.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading records.parquet from webpresence-geocore-geojson-to-parquet-dev to pandas dataframe\n"
     ]
    }
   ],
   "source": [
    "# Read the original parquet file and merge by features_properties_id\n",
    "file_name_origianl = \"records.parquet\"\n",
    "bucket_name = \"webpresence-geocore-geojson-to-parquet-dev\"\n",
    "df_original = open_S3_file_as_df(bucket_name, file_name_origianl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original.head()\n",
    "print(df_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7343, 73)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features_type</th>\n",
       "      <th>features_geometry_type</th>\n",
       "      <th>features_geometry_coordinates</th>\n",
       "      <th>features_properties_id</th>\n",
       "      <th>features_properties_title_en</th>\n",
       "      <th>features_properties_title_fr</th>\n",
       "      <th>features_properties_description_en</th>\n",
       "      <th>features_properties_description_fr</th>\n",
       "      <th>features_properties_keywords_en</th>\n",
       "      <th>features_properties_keywords_fr</th>\n",
       "      <th>...</th>\n",
       "      <th>features_properties_temporalExtent_end_@indeterminatePosition</th>\n",
       "      <th>features_properties_temporalExtent_end_#text</th>\n",
       "      <th>features_properties_plugins</th>\n",
       "      <th>features_properties_sourceSystemName</th>\n",
       "      <th>features_popularity</th>\n",
       "      <th>sim1</th>\n",
       "      <th>sim2</th>\n",
       "      <th>sim3</th>\n",
       "      <th>sim4</th>\n",
       "      <th>sim5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>[[[-141.003, 41.6755], [-52.6174, 41.6755], [-...</td>\n",
       "      <td>000183ed-8864-42f0-ae43-c4313a860720</td>\n",
       "      <td>Principal Mineral Areas, Producing Mines, and ...</td>\n",
       "      <td>Principales régions minières, principales mine...</td>\n",
       "      <td>This dataset is produced and published annuall...</td>\n",
       "      <td>Ce jeu de données est produit et publié annuel...</td>\n",
       "      <td>mineralization, mineral occurrences, mines, hy...</td>\n",
       "      <td>minéralisation, indices minéralisés, mines, hy...</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1250806</td>\n",
       "      <td>b64179f3-ea0f-4abb-9cc5-85432fc958a0</td>\n",
       "      <td>22b2db8a-dc12-47f2-9737-99d3da921751</td>\n",
       "      <td>8db08fa3-a181-4d9b-b091-0f65270ff18b</td>\n",
       "      <td>7ce2ed0c-cb87-463d-83aa-7ed62a672792</td>\n",
       "      <td>e2b6e799-9f29-87c4-0143-6c7505978508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>[[[-142, 41], [-52, 41], [-52, 84], [-142, 84]...</td>\n",
       "      <td>7f245e4d-76c2-4caa-951a-45d1d2051333</td>\n",
       "      <td>Canadian Digital Elevation Model, 1945-2011</td>\n",
       "      <td>Modèle numérique d'élévation du Canada, 1945-2011</td>\n",
       "      <td>This collection is a legacy product that is no...</td>\n",
       "      <td>Ce produit fait maintenant partie du patrimoin...</td>\n",
       "      <td>Canada, Earth Sciences, elevation, relief, geo...</td>\n",
       "      <td>Canada, Sciences de la Terre, élévation, relie...</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>210798</td>\n",
       "      <td>768570f8-5761-498a-bd6a-315eb6cc023d</td>\n",
       "      <td>0fe65119-e96e-4a57-8bfe-9d9245fba06b</td>\n",
       "      <td>f5c4e4af-ddc5-4f54-a70b-8390e4a4268e</td>\n",
       "      <td>ff383f5c-0772-46f3-84df-c2cb860d0da2</td>\n",
       "      <td>4ff9312f-a200-4fe6-aac3-00a803afa5d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>[[[-141.003, 41.6755], [-52.6174, 41.6755], [-...</td>\n",
       "      <td>085024ac-5a48-427a-a2ea-d62af73f2142</td>\n",
       "      <td>Canada's National Earthquake Scenario Catalogue</td>\n",
       "      <td>Catalogue national de scénarios de tremblement...</td>\n",
       "      <td>The National Earthquake Scenario Catalogue, pr...</td>\n",
       "      <td>Le dépôt est utilisé pour l’élaboration du cat...</td>\n",
       "      <td>Emergency preparedness, Earth sciences, Earthq...</td>\n",
       "      <td>Protection civile, Sciences de la terre, Tremb...</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>140088</td>\n",
       "      <td>79fdad93-9025-49ad-ba16-c26d718cc070</td>\n",
       "      <td>f2d6263a-8b65-4350-9515-345875c6bebf</td>\n",
       "      <td>2364749d-70a0-4874-956d-a636401ac5a6</td>\n",
       "      <td>ee421d50-dffd-41fb-976c-5bbfec04b2dd</td>\n",
       "      <td>4cedd37e-0023-41fe-8eff-bea45385e469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>[[[-104.75571511, 50.42392886], [-104.56356008...</td>\n",
       "      <td>03ccfb5c-a06e-43e3-80fd-09d4f8f69703</td>\n",
       "      <td>Temporal Series of the National Air Photo Libr...</td>\n",
       "      <td>Série temporelle de la photothèque nationale d...</td>\n",
       "      <td>Note: To visualize the data in the viewer, zoo...</td>\n",
       "      <td>Note: Pour visualiser les données dans l’outil...</td>\n",
       "      <td>Mosaic, Aerial photography, Access to informat...</td>\n",
       "      <td>Mosaïque, Photographie aérienne, Accès à l'inf...</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>120162</td>\n",
       "      <td>230f1f6d-353e-4d02-800b-368f4c48dc86</td>\n",
       "      <td>d8627209-bda2-436f-b22b-0eb19fdc6660</td>\n",
       "      <td>4e8e3c6a-c961-4def-bdc7-f24823462818</td>\n",
       "      <td>f129611d-7ca1-418b-8390-ebac5adf958e</td>\n",
       "      <td>f498bb69-3982-4b62-94db-4c0e0065bc17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feature</td>\n",
       "      <td>Polygon</td>\n",
       "      <td>[[[-141.003, 41.6755], [-52.6174, 41.6755], [-...</td>\n",
       "      <td>488faf70-b50b-4749-ac1c-a1fd44e06f11</td>\n",
       "      <td>Indigenous Mining Agreements</td>\n",
       "      <td>Ententes minières autochtones</td>\n",
       "      <td>The Indigenous Mining Agreements dataset provi...</td>\n",
       "      <td>Les données des ententes minières autochtones ...</td>\n",
       "      <td>Indigenous, First Nations, Métis, Indigenous a...</td>\n",
       "      <td>Autochtones, Premières nations, Métis, Affaire...</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>111036</td>\n",
       "      <td>CGDIWH-118602</td>\n",
       "      <td>82cad281-ff7d-47b3-b2ce-9f794257e86d</td>\n",
       "      <td>CGDIWH-150333</td>\n",
       "      <td>498a6086-e7c3-440c-b4d3-22fc6c5599a9</td>\n",
       "      <td>fa542137-a976-49a6-856d-f1201adb2243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  features_type features_geometry_type  \\\n",
       "0       Feature                Polygon   \n",
       "1       Feature                Polygon   \n",
       "2       Feature                Polygon   \n",
       "3       Feature                Polygon   \n",
       "4       Feature                Polygon   \n",
       "\n",
       "                       features_geometry_coordinates  \\\n",
       "0  [[[-141.003, 41.6755], [-52.6174, 41.6755], [-...   \n",
       "1  [[[-142, 41], [-52, 41], [-52, 84], [-142, 84]...   \n",
       "2  [[[-141.003, 41.6755], [-52.6174, 41.6755], [-...   \n",
       "3  [[[-104.75571511, 50.42392886], [-104.56356008...   \n",
       "4  [[[-141.003, 41.6755], [-52.6174, 41.6755], [-...   \n",
       "\n",
       "                 features_properties_id  \\\n",
       "0  000183ed-8864-42f0-ae43-c4313a860720   \n",
       "1  7f245e4d-76c2-4caa-951a-45d1d2051333   \n",
       "2  085024ac-5a48-427a-a2ea-d62af73f2142   \n",
       "3  03ccfb5c-a06e-43e3-80fd-09d4f8f69703   \n",
       "4  488faf70-b50b-4749-ac1c-a1fd44e06f11   \n",
       "\n",
       "                        features_properties_title_en  \\\n",
       "0  Principal Mineral Areas, Producing Mines, and ...   \n",
       "1        Canadian Digital Elevation Model, 1945-2011   \n",
       "2    Canada's National Earthquake Scenario Catalogue   \n",
       "3  Temporal Series of the National Air Photo Libr...   \n",
       "4                       Indigenous Mining Agreements   \n",
       "\n",
       "                        features_properties_title_fr  \\\n",
       "0  Principales régions minières, principales mine...   \n",
       "1  Modèle numérique d'élévation du Canada, 1945-2011   \n",
       "2  Catalogue national de scénarios de tremblement...   \n",
       "3  Série temporelle de la photothèque nationale d...   \n",
       "4                      Ententes minières autochtones   \n",
       "\n",
       "                  features_properties_description_en  \\\n",
       "0  This dataset is produced and published annuall...   \n",
       "1  This collection is a legacy product that is no...   \n",
       "2  The National Earthquake Scenario Catalogue, pr...   \n",
       "3  Note: To visualize the data in the viewer, zoo...   \n",
       "4  The Indigenous Mining Agreements dataset provi...   \n",
       "\n",
       "                  features_properties_description_fr  \\\n",
       "0  Ce jeu de données est produit et publié annuel...   \n",
       "1  Ce produit fait maintenant partie du patrimoin...   \n",
       "2  Le dépôt est utilisé pour l’élaboration du cat...   \n",
       "3  Note: Pour visualiser les données dans l’outil...   \n",
       "4  Les données des ententes minières autochtones ...   \n",
       "\n",
       "                     features_properties_keywords_en  \\\n",
       "0  mineralization, mineral occurrences, mines, hy...   \n",
       "1  Canada, Earth Sciences, elevation, relief, geo...   \n",
       "2  Emergency preparedness, Earth sciences, Earthq...   \n",
       "3  Mosaic, Aerial photography, Access to informat...   \n",
       "4  Indigenous, First Nations, Métis, Indigenous a...   \n",
       "\n",
       "                     features_properties_keywords_fr  ...  \\\n",
       "0  minéralisation, indices minéralisés, mines, hy...  ...   \n",
       "1  Canada, Sciences de la Terre, élévation, relie...  ...   \n",
       "2  Protection civile, Sciences de la terre, Tremb...  ...   \n",
       "3  Mosaïque, Photographie aérienne, Accès à l'inf...  ...   \n",
       "4  Autochtones, Premières nations, Métis, Affaire...  ...   \n",
       "\n",
       "  features_properties_temporalExtent_end_@indeterminatePosition  \\\n",
       "0                                               <NA>              \n",
       "1                                               <NA>              \n",
       "2                                               <NA>              \n",
       "3                                               <NA>              \n",
       "4                                               <NA>              \n",
       "\n",
       "  features_properties_temporalExtent_end_#text features_properties_plugins  \\\n",
       "0                                         <NA>                          []   \n",
       "1                                         <NA>                          []   \n",
       "2                                         <NA>                          []   \n",
       "3                                         <NA>                          []   \n",
       "4                                         <NA>                          []   \n",
       "\n",
       "  features_properties_sourceSystemName features_popularity  \\\n",
       "0                                 <NA>             1250806   \n",
       "1                                 <NA>              210798   \n",
       "2                                 <NA>              140088   \n",
       "3                                 <NA>              120162   \n",
       "4                                 <NA>              111036   \n",
       "\n",
       "                                   sim1                                  sim2  \\\n",
       "0  b64179f3-ea0f-4abb-9cc5-85432fc958a0  22b2db8a-dc12-47f2-9737-99d3da921751   \n",
       "1  768570f8-5761-498a-bd6a-315eb6cc023d  0fe65119-e96e-4a57-8bfe-9d9245fba06b   \n",
       "2  79fdad93-9025-49ad-ba16-c26d718cc070  f2d6263a-8b65-4350-9515-345875c6bebf   \n",
       "3  230f1f6d-353e-4d02-800b-368f4c48dc86  d8627209-bda2-436f-b22b-0eb19fdc6660   \n",
       "4                         CGDIWH-118602  82cad281-ff7d-47b3-b2ce-9f794257e86d   \n",
       "\n",
       "                                   sim3                                  sim4  \\\n",
       "0  8db08fa3-a181-4d9b-b091-0f65270ff18b  7ce2ed0c-cb87-463d-83aa-7ed62a672792   \n",
       "1  f5c4e4af-ddc5-4f54-a70b-8390e4a4268e  ff383f5c-0772-46f3-84df-c2cb860d0da2   \n",
       "2  2364749d-70a0-4874-956d-a636401ac5a6  ee421d50-dffd-41fb-976c-5bbfec04b2dd   \n",
       "3  4e8e3c6a-c961-4def-bdc7-f24823462818  f129611d-7ca1-418b-8390-ebac5adf958e   \n",
       "4                         CGDIWH-150333  498a6086-e7c3-440c-b4d3-22fc6c5599a9   \n",
       "\n",
       "                                   sim5  \n",
       "0  e2b6e799-9f29-87c4-0143-6c7505978508  \n",
       "1  4ff9312f-a200-4fe6-aac3-00a803afa5d9  \n",
       "2  4cedd37e-0023-41fe-8eff-bea45385e469  \n",
       "3  f498bb69-3982-4b62-94db-4c0e0065bc17  \n",
       "4  fa542137-a976-49a6-856d-f1201adb2243  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = df_original.merge(df[['features_properties_id', 'sim1', 'sim2', 'sim3', 'sim4', 'sim5']], on='features_properties_id', how='left')\n",
    "print(merged_df.shape)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out merged data to csv\n",
    "#merged_df.to_csv('sim_word2vec_records.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading sim_word2vec_records.parquet to nlp-data-preprocessing as parquet file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload the parquet file to S3\n",
    "# Upload the duplicate date to S3 as a parquet file \n",
    "def upload_dataframe_to_s3_as_parquet(df, bucket_name, file_key):\n",
    "    # Save DataFrame as a Parquet file locally\n",
    "    parquet_file_path = 'temp.parquet'\n",
    "    df.to_parquet(parquet_file_path, index=False)  # Set index to False\n",
    "\n",
    "    # Create an S3 client\n",
    "    s3_client = boto3.client('s3')\n",
    "\n",
    "    # Upload the Parquet file to S3 bucket\n",
    "    try:\n",
    "        response = s3_client.upload_file(parquet_file_path, bucket_name, file_key)\n",
    "        os.remove(parquet_file_path)\n",
    "        print(f'Uploading {file_key} to {bucket_name} as parquet file')\n",
    "        # Delete the local Parquet file\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "upload_dataframe_to_s3_as_parquet(df=merged_df, bucket_name=bucket_name_nlp, file_key='sim_word2vec_records.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize similarity scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the similarity matrix for selcted records\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Select the first 5 rows\n",
    "selected_vectors = vectors[:5]\n",
    "\n",
    "# Calculate similarity between selected vectors\n",
    "selected_similarity_matrix = cosine_similarity(selected_vectors)\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "similarity_df = pd.DataFrame(selected_similarity_matrix, \n",
    "                             columns=df['features_properties_title_en'][:5],\n",
    "                             index=df['features_properties_title_en'][:5])\n",
    "\n",
    "# Visualize the similarity scores in a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(similarity_df, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Similarity Scores for Selected Rows\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT from transformer library \n",
    "The BERT (Bidirectional Encoder Representations from Transformers) model is a transformer-based machine learning technique for natural language processing (NLP) tasks. BERT is a deep- learning model \n",
    "\n",
    "We can use the transformers library developed by Hugging Face to work with BERT and other transformer models. This library provides pre-trained models for BERT and many other popular transformer models, and it's straightforward to use for tasks such as text classification, named entity recognition, and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install transformers\n",
    "#pip install torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the BERT model\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to calculate embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :].detach().numpy()  # we take the embedding of the [CLS] token\n",
    "    return embeddings\n",
    "\n",
    "# Calculate embeddings for each text\n",
    "df['embeddings'] = df['metadata_en_processed'].apply(calculate_embedding)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_matrix = cosine_similarity(np.vstack(df['embeddings']))\n",
    "\n",
    "# Find top 5 most similar texts for each text\n",
    "df['top_5_similar'] = [list(df.iloc[np.argsort(-row)][1:6].index) for row in similarity_matrix]"
   ]

  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CustomModel and load finetuned model from path.\n",
    "import sys\n",
    "import argparse\n",
    "import torch\n",
    "sys.path.append(\"/home/rsaha/projects/similarity-engine/src/\")\n",
    "sys.path.append(\"/home/rsaha/projects/similarity-engine/src/models/\")\n",
    "from custom_model import CustomModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "argparse = argparse.ArgumentParser(description='arguments in ipynb')\n",
    "\n",
    "# Add arguments to the parser.\n",
    "argparse.add_argument('--model_name', type=str, default='bert-base-uncased')\n",
    "argparse.add_argument('--model_type', type=str, default='bert')\n",
    "argparse.add_argument('--batch_size', type=int, default=8)\n",
    "argparse.add_argument('--epochs', type=int, default=3)\n",
    "argparse.add_argument('--lr', type=float, default=2e-5)\n",
    "argparse.add_argument('--load_model_path', type=str, default='')\n",
    "\n",
    "\n",
    "args = argparse.parse_args('')\n",
    "args.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.load_model_path = \"/home/rsaha/projects/similarity-engine/saved_models/trainer_bert_fine_tune/checkpoint-4000/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = CustomModel(args, load_model_from_path=False, model_path=args.load_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []

  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",

   "version": "3.7.5"

  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
